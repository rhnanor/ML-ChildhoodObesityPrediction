{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMr+Z44L9BZ5uMIgJpXRaBA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhnanor/ML-ChildhoodObesityPrediction/blob/main/takjadi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3yMAG8TV9pGl"
      },
      "outputs": [],
      "source": [
        "#Import Libraries :\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.axes as ax"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "data = pd.read_csv('/content/data2.csv')"
      ],
      "metadata": {
        "id": "1XID75-r98mn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training dataset and labels\n",
        "train_input = np.array(data.iloc[0:500 :8])  # Extract the first 500 rows and all 8 columns as input features\n",
        "train_output = np.array(data.iloc[0:500, 8:])  # Extract the first 500 rows and the remaining columns as output labels\n",
        "\n",
        "# Validation dataset and labels\n",
        "test_input = np.array(data.iloc[500:700, :8])  # Extract rows 500 to 699 and all 8 columns as input features\n",
        "test_output = np.array(data.iloc[500:700, 8:])  # Extract rows 500 to 699 and the remaining columns as output labels"
      ],
      "metadata": {
        "id": "afj74nMI-rcc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "    def __init__(self):\n",
        "        self.parameters = {}\n",
        "     \n",
        "    def forward_propagation(self, train_input):\n",
        "        m = self.parameters['m']\n",
        "        c = self.parameters['c']\n",
        "        predictions = np.multiply(m, train_input) + c\n",
        "        return predictions\n",
        " \n",
        "    def cost_function(self, predictions, train_output):\n",
        "        cost = np.mean((train_output - predictions) ** 2)\n",
        "        return cost\n",
        " \n",
        "    def backward_propagation(self, train_input, train_output, predictions):\n",
        "        derivatives = {}\n",
        "        df = (train_output - predictions) * -1\n",
        "        dm = np.mean(np.multiply(train_input, df))\n",
        "        dc = np.mean(df)\n",
        "        derivatives['dm'] = dm\n",
        "        derivatives['dc'] = dc\n",
        "        return derivatives\n",
        " \n",
        "    def update_parameters(self, derivatives, learning_rate):\n",
        "        self.parameters['m'] = self.parameters['m'] - learning_rate * derivatives['dm']\n",
        "        self.parameters['c'] = self.parameters['c'] - learning_rate * derivatives['dc']\n",
        " \n",
        "    def train(self, train_input, train_output, learning_rate, iters):\n",
        "        #initialize random parameters\n",
        "        self.parameters['m'] = np.random.uniform(0,1) * -1\n",
        "        self.parameters['c'] = np.random.uniform(0,1) * -1\n",
        "         \n",
        "        #initialize loss\n",
        "        self.loss = []\n",
        "         \n",
        "        #iterate\n",
        "        for i in range(iters):\n",
        "            #forward propagation\n",
        "            predictions = self.forward_propagation(train_input)\n",
        " \n",
        "            #cost function\n",
        "            cost = self.cost_function(predictions, train_output)\n",
        " \n",
        "            #append loss and print\n",
        "            self.loss.append(cost)\n",
        "            print(\"Iteration = {}, Loss = {}\".format(i+1, cost))\n",
        " \n",
        "            #back propagation\n",
        "            derivatives = self.backward_propagation(train_input, train_output, predictions)\n",
        " \n",
        "            #update parameters\n",
        "            self.update_parameters(derivatives, learning_rate)\n",
        " \n",
        "        return self.parameters, self.loss"
      ],
      "metadata": {
        "id": "pnYGbyoj-fOb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example usage\n",
        "linear_reg = LinearRegression()\n",
        "parameters, loss = linear_reg.train(train_input, train_output, 0.01, 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "4jAc40xP-mJH",
        "outputId": "e10c7f49-7278-4a9e-95fc-209e48b4972d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-16afb5f160dc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Example usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlinear_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-4bf0dff547f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_input, train_output, learning_rate, iters)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#append loss and print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4bf0dff547f5>\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(self, predictions, train_output)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_output\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (500,1) (63,9) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on test data\n",
        "y_pred = test_input*parameters['m'] + parameters['c']\n",
        " \n",
        "# Plot the regression line with actual data pointa\n",
        "plt.plot(test_input, test_output, '+', label='Actual values')\n",
        "plt.plot(test_input, y_pred, label='Predicted values')\n",
        "plt.xlabel('Test input')\n",
        "plt.ylabel('Test Output or Predicted output')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jqGgrsGx-2Ir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "37048ee7-4d80-4005-d170-de5a7e815b74"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fe467fc7dd8c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Prediction on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'm'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Plot the regression line with actual data pointa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Actual values'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
          ]
        }
      ]
    }
  ]
}